{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea0cf77",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772d064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f8bb0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\user\\anaconda3\\lib\\site-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca3ce22",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2078eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf0767",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ca2d8e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\user\\\\Downloads\\\\forestfires(1).csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce24c03",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b0bf1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2e8c4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f07367f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517</td>\n",
       "      <td>517</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>184</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       month  day        FFMC         DMC          DC         ISI        temp  \\\n",
       "count    517  517  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "unique    12    7         NaN         NaN         NaN         NaN         NaN   \n",
       "top      aug  sun         NaN         NaN         NaN         NaN         NaN   \n",
       "freq     184   95         NaN         NaN         NaN         NaN         NaN   \n",
       "mean     NaN  NaN   90.644681  110.872340  547.940039    9.021663   18.889168   \n",
       "std      NaN  NaN    5.520111   64.046482  248.066192    4.559477    5.806625   \n",
       "min      NaN  NaN   18.700000    1.100000    7.900000    0.000000    2.200000   \n",
       "25%      NaN  NaN   90.200000   68.600000  437.700000    6.500000   15.500000   \n",
       "50%      NaN  NaN   91.600000  108.300000  664.200000    8.400000   19.300000   \n",
       "75%      NaN  NaN   92.900000  142.400000  713.900000   10.800000   22.800000   \n",
       "max      NaN  NaN   96.200000  291.300000  860.600000   56.100000   33.300000   \n",
       "\n",
       "                RH        wind        rain  ...    monthfeb    monthjan  \\\n",
       "count   517.000000  517.000000  517.000000  ...  517.000000  517.000000   \n",
       "unique         NaN         NaN         NaN  ...         NaN         NaN   \n",
       "top            NaN         NaN         NaN  ...         NaN         NaN   \n",
       "freq           NaN         NaN         NaN  ...         NaN         NaN   \n",
       "mean     44.288201    4.017602    0.021663  ...    0.038685    0.003868   \n",
       "std      16.317469    1.791653    0.295959  ...    0.193029    0.062137   \n",
       "min      15.000000    0.400000    0.000000  ...    0.000000    0.000000   \n",
       "25%      33.000000    2.700000    0.000000  ...    0.000000    0.000000   \n",
       "50%      42.000000    4.000000    0.000000  ...    0.000000    0.000000   \n",
       "75%      53.000000    4.900000    0.000000  ...    0.000000    0.000000   \n",
       "max     100.000000    9.400000    6.400000  ...    1.000000    1.000000   \n",
       "\n",
       "          monthjul    monthjun    monthmar    monthmay    monthnov  \\\n",
       "count   517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "unique         NaN         NaN         NaN         NaN         NaN   \n",
       "top            NaN         NaN         NaN         NaN         NaN   \n",
       "freq           NaN         NaN         NaN         NaN         NaN   \n",
       "mean      0.061896    0.032882    0.104449    0.003868    0.001934   \n",
       "std       0.241199    0.178500    0.306138    0.062137    0.043980   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max       1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          monthoct    monthsep  size_category  \n",
       "count   517.000000  517.000000            517  \n",
       "unique         NaN         NaN              2  \n",
       "top            NaN         NaN          small  \n",
       "freq           NaN         NaN            378  \n",
       "mean      0.029014    0.332689            NaN  \n",
       "std       0.168007    0.471632            NaN  \n",
       "min       0.000000    0.000000            NaN  \n",
       "25%       0.000000    0.000000            NaN  \n",
       "50%       0.000000    0.000000            NaN  \n",
       "75%       0.000000    1.000000            NaN  \n",
       "max       1.000000    1.000000            NaN  \n",
       "\n",
       "[11 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c126a4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month             object\n",
       "day               object\n",
       "FFMC             float64\n",
       "DMC              float64\n",
       "DC               float64\n",
       "ISI              float64\n",
       "temp             float64\n",
       "RH                 int64\n",
       "wind             float64\n",
       "rain             float64\n",
       "area             float64\n",
       "dayfri             int64\n",
       "daymon             int64\n",
       "daysat             int64\n",
       "daysun             int64\n",
       "daythu             int64\n",
       "daytue             int64\n",
       "daywed             int64\n",
       "monthapr           int64\n",
       "monthaug           int64\n",
       "monthdec           int64\n",
       "monthfeb           int64\n",
       "monthjan           int64\n",
       "monthjul           int64\n",
       "monthjun           int64\n",
       "monthmar           int64\n",
       "monthmay           int64\n",
       "monthnov           int64\n",
       "monthoct           int64\n",
       "monthsep           int64\n",
       "size_category     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6d20a",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "\n",
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61622b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaling the numerical data( leaving the target variable )\n",
    "df1=df.iloc[:,2:30]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "df_norm=sc.fit_transform(df1)\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122760c",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e42d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  4.98037274e-16, -2.73530281e-16],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02, -9.55928328e-15,  1.15055466e-15],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  2.58690766e-15, -5.66797432e-17],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01, -1.84247930e-16,  2.36645381e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02, -2.30354869e-16,  2.72058887e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  5.70142521e-17,  8.50237385e-17]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=28)\n",
    "pca_values=pca.fit_transform(df_norm)\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ab3338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 1.95971390e-33])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var=pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5349dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d9ad10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1=np.cumsum(np.round(var,decimals=4)*100)\n",
    "var1\n",
    "\n",
    "#Return the cumulative sum of the elements along a given axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f789abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19372c454c0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(var1,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b143d8",
   "metadata": {},
   "source": [
    "**hence here we will choose 24 pcs outoff 28 for further procedure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "764fe00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf=pd.concat([pd.DataFrame(pca_values[:,0:24],columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']),\n",
    "                 df[['size_category']]], axis = 1)\n",
    "finaldf.size_category.replace(('large','small'),(1,0),inplace=True)\n",
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a62c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into x and y\n",
    "array=finaldf.values\n",
    "x=array[:,0:24]\n",
    "y=array[:,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "831a73f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e2508",
   "metadata": {},
   "source": [
    "**iteration=1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b0c1d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 1s 9ms/step - loss: 0.6957 - accuracy: 0.5429 - val_loss: 0.6778 - val_accuracy: 0.5962\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6814 - val_loss: 0.6550 - val_accuracy: 0.6795\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7396 - val_loss: 0.6479 - val_accuracy: 0.6795\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7535 - val_loss: 0.6461 - val_accuracy: 0.6795\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7618 - val_loss: 0.6463 - val_accuracy: 0.6667\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7701 - val_loss: 0.6488 - val_accuracy: 0.6731\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7756 - val_loss: 0.6418 - val_accuracy: 0.6731\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7867 - val_loss: 0.6436 - val_accuracy: 0.6795\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.7867 - val_loss: 0.6432 - val_accuracy: 0.6731\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7895 - val_loss: 0.6391 - val_accuracy: 0.6731\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7922 - val_loss: 0.6422 - val_accuracy: 0.6731\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7950 - val_loss: 0.6410 - val_accuracy: 0.6731\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7950 - val_loss: 0.6341 - val_accuracy: 0.6795\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.7978 - val_loss: 0.6408 - val_accuracy: 0.6795\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7950 - val_loss: 0.6414 - val_accuracy: 0.6795\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7922 - val_loss: 0.6471 - val_accuracy: 0.6795\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7978 - val_loss: 0.6455 - val_accuracy: 0.6795\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7978 - val_loss: 0.6508 - val_accuracy: 0.6859\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7978 - val_loss: 0.6471 - val_accuracy: 0.6923\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8006 - val_loss: 0.6482 - val_accuracy: 0.6923\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8006 - val_loss: 0.6476 - val_accuracy: 0.6923\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.8006 - val_loss: 0.6451 - val_accuracy: 0.6923\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8006 - val_loss: 0.6458 - val_accuracy: 0.6795\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.8006 - val_loss: 0.6482 - val_accuracy: 0.6731\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8006 - val_loss: 0.6466 - val_accuracy: 0.6731\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8006 - val_loss: 0.6456 - val_accuracy: 0.6731\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8006 - val_loss: 0.6480 - val_accuracy: 0.6731\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8033 - val_loss: 0.6489 - val_accuracy: 0.6731\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8061 - val_loss: 0.6427 - val_accuracy: 0.6731\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8033 - val_loss: 0.6518 - val_accuracy: 0.6731\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8089 - val_loss: 0.6373 - val_accuracy: 0.6731\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8172 - val_loss: 0.6401 - val_accuracy: 0.6603\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8172 - val_loss: 0.6448 - val_accuracy: 0.6731\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8227 - val_loss: 0.6448 - val_accuracy: 0.6667\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8366 - val_loss: 0.6435 - val_accuracy: 0.6731\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8255 - val_loss: 0.6533 - val_accuracy: 0.6731\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3609 - accuracy: 0.8421 - val_loss: 0.6514 - val_accuracy: 0.6731\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.8476 - val_loss: 0.6416 - val_accuracy: 0.6731\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8504 - val_loss: 0.6454 - val_accuracy: 0.6731\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8504 - val_loss: 0.6507 - val_accuracy: 0.6667\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8421 - val_loss: 0.6543 - val_accuracy: 0.6667\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8476 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8698 - val_loss: 0.6579 - val_accuracy: 0.6795\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.3220 - accuracy: 0.8615 - val_loss: 0.6634 - val_accuracy: 0.6859\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3180 - accuracy: 0.8753 - val_loss: 0.6599 - val_accuracy: 0.6987\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3105 - accuracy: 0.8726 - val_loss: 0.6701 - val_accuracy: 0.6987\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3059 - accuracy: 0.8698 - val_loss: 0.6685 - val_accuracy: 0.7115\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3036 - accuracy: 0.8643 - val_loss: 0.6729 - val_accuracy: 0.7179\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.2976 - accuracy: 0.8698 - val_loss: 0.6742 - val_accuracy: 0.7179\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2898 - accuracy: 0.8837 - val_loss: 0.6782 - val_accuracy: 0.7244\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.8809 - val_loss: 0.6819 - val_accuracy: 0.7244\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.8781 - val_loss: 0.6800 - val_accuracy: 0.7179\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.8864 - val_loss: 0.6798 - val_accuracy: 0.7115\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8809 - val_loss: 0.6825 - val_accuracy: 0.7179\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.8947 - val_loss: 0.6883 - val_accuracy: 0.7051\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.8920 - val_loss: 0.6916 - val_accuracy: 0.7051\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9058 - val_loss: 0.6952 - val_accuracy: 0.7115\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.9169 - val_loss: 0.6968 - val_accuracy: 0.7115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.9141 - val_loss: 0.6967 - val_accuracy: 0.7051\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2416 - accuracy: 0.9197 - val_loss: 0.6960 - val_accuracy: 0.7051\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2364 - accuracy: 0.9224 - val_loss: 0.7015 - val_accuracy: 0.7051\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2293 - accuracy: 0.9197 - val_loss: 0.7044 - val_accuracy: 0.6987\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2243 - accuracy: 0.9197 - val_loss: 0.7111 - val_accuracy: 0.6987\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2208 - accuracy: 0.9252 - val_loss: 0.7166 - val_accuracy: 0.6987\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2163 - accuracy: 0.9252 - val_loss: 0.7213 - val_accuracy: 0.7051\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.9280 - val_loss: 0.7297 - val_accuracy: 0.7179\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2083 - accuracy: 0.9224 - val_loss: 0.7326 - val_accuracy: 0.7115\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 0.9252 - val_loss: 0.7320 - val_accuracy: 0.7244\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1999 - accuracy: 0.9363 - val_loss: 0.7391 - val_accuracy: 0.7308\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1951 - accuracy: 0.9363 - val_loss: 0.7413 - val_accuracy: 0.7308\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9307 - val_loss: 0.7449 - val_accuracy: 0.7308\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1886 - accuracy: 0.9418 - val_loss: 0.7503 - val_accuracy: 0.7372\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1843 - accuracy: 0.9446 - val_loss: 0.7542 - val_accuracy: 0.7372\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1806 - accuracy: 0.9363 - val_loss: 0.7564 - val_accuracy: 0.7308\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1780 - accuracy: 0.9446 - val_loss: 0.7586 - val_accuracy: 0.7372\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1732 - accuracy: 0.9418 - val_loss: 0.7612 - val_accuracy: 0.7372\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9474 - val_loss: 0.7727 - val_accuracy: 0.7244\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1672 - accuracy: 0.9446 - val_loss: 0.7676 - val_accuracy: 0.7308\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1654 - accuracy: 0.9446 - val_loss: 0.7688 - val_accuracy: 0.7436\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1624 - accuracy: 0.9474 - val_loss: 0.7711 - val_accuracy: 0.7500\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1604 - accuracy: 0.9557 - val_loss: 0.7766 - val_accuracy: 0.7500\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1657 - accuracy: 0.9501 - val_loss: 0.7764 - val_accuracy: 0.7436\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9529 - val_loss: 0.7829 - val_accuracy: 0.7436\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9529 - val_loss: 0.7781 - val_accuracy: 0.7564\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1459 - accuracy: 0.9584 - val_loss: 0.7868 - val_accuracy: 0.7436\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9584 - val_loss: 0.7839 - val_accuracy: 0.7500\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9584 - val_loss: 0.7922 - val_accuracy: 0.7564\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.9584 - val_loss: 0.7985 - val_accuracy: 0.7564\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9612 - val_loss: 0.8032 - val_accuracy: 0.7628\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9557 - val_loss: 0.8072 - val_accuracy: 0.7628\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9584 - val_loss: 0.8027 - val_accuracy: 0.7564\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1332 - accuracy: 0.9584 - val_loss: 0.8079 - val_accuracy: 0.7628\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.9584 - val_loss: 0.8188 - val_accuracy: 0.7756\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.9584 - val_loss: 0.8237 - val_accuracy: 0.7756\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9640 - val_loss: 0.8173 - val_accuracy: 0.7692\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9612 - val_loss: 0.8267 - val_accuracy: 0.7756\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.9557 - val_loss: 0.8288 - val_accuracy: 0.7821\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9557 - val_loss: 0.8397 - val_accuracy: 0.7692\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9612 - val_loss: 0.8437 - val_accuracy: 0.7756\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.9584 - val_loss: 0.8463 - val_accuracy: 0.7821\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1092 - accuracy: 0.9668 - val_loss: 0.8586 - val_accuracy: 0.7821\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9640 - val_loss: 0.8425 - val_accuracy: 0.7821\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9640 - val_loss: 0.8546 - val_accuracy: 0.7885\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.1066 - accuracy: 0.9584 - val_loss: 0.8637 - val_accuracy: 0.7821\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9751 - val_loss: 0.8670 - val_accuracy: 0.7885\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.9584 - val_loss: 0.8747 - val_accuracy: 0.7885\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9695 - val_loss: 0.8778 - val_accuracy: 0.7885\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9640 - val_loss: 0.8881 - val_accuracy: 0.7885\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9695 - val_loss: 0.8939 - val_accuracy: 0.7885\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9806 - val_loss: 0.8952 - val_accuracy: 0.7885\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9751 - val_loss: 0.8995 - val_accuracy: 0.7885\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9778 - val_loss: 0.9065 - val_accuracy: 0.7821\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9695 - val_loss: 0.9065 - val_accuracy: 0.7885\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9806 - val_loss: 0.9188 - val_accuracy: 0.7885\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9778 - val_loss: 0.9116 - val_accuracy: 0.7949\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9778 - val_loss: 0.9169 - val_accuracy: 0.8013\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9778 - val_loss: 0.9171 - val_accuracy: 0.8013\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9834 - val_loss: 0.9257 - val_accuracy: 0.7949\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9861 - val_loss: 0.9301 - val_accuracy: 0.7949\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 0.9778 - val_loss: 0.9281 - val_accuracy: 0.7949\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9751 - val_loss: 0.9459 - val_accuracy: 0.7949\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9834 - val_loss: 0.9506 - val_accuracy: 0.7885\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9778 - val_loss: 0.9561 - val_accuracy: 0.7821\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9834 - val_loss: 0.9556 - val_accuracy: 0.7949\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9834 - val_loss: 0.9640 - val_accuracy: 0.7885\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9834 - val_loss: 0.9678 - val_accuracy: 0.7821\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9834 - val_loss: 0.9668 - val_accuracy: 0.7885\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9834 - val_loss: 0.9781 - val_accuracy: 0.7821\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9806 - val_loss: 0.9817 - val_accuracy: 0.7821\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9861 - val_loss: 0.9911 - val_accuracy: 0.7949\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9861 - val_loss: 0.9969 - val_accuracy: 0.7821\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9806 - val_loss: 0.9985 - val_accuracy: 0.7821\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9889 - val_loss: 1.0066 - val_accuracy: 0.7821\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0573 - accuracy: 0.9889 - val_loss: 1.0101 - val_accuracy: 0.7821\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9834 - val_loss: 1.0182 - val_accuracy: 0.7821\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9917 - val_loss: 1.0196 - val_accuracy: 0.7821\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9889 - val_loss: 1.0296 - val_accuracy: 0.7756\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9889 - val_loss: 1.0301 - val_accuracy: 0.7821\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9861 - val_loss: 1.0384 - val_accuracy: 0.7756\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9889 - val_loss: 1.0209 - val_accuracy: 0.7756\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9889 - val_loss: 1.0356 - val_accuracy: 0.7756\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0480 - accuracy: 0.9945 - val_loss: 1.0480 - val_accuracy: 0.7756\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9972 - val_loss: 1.0552 - val_accuracy: 0.7756\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9972 - val_loss: 1.0581 - val_accuracy: 0.7756\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9945 - val_loss: 1.0708 - val_accuracy: 0.7821\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9972 - val_loss: 1.0764 - val_accuracy: 0.7821\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9972 - val_loss: 1.0781 - val_accuracy: 0.7756\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9889 - val_loss: 1.0902 - val_accuracy: 0.7756\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9945 - val_loss: 1.0930 - val_accuracy: 0.7821\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.0414 - accuracy: 0.9945 - val_loss: 1.1010 - val_accuracy: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1936c59abb0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=24,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(x,y, validation_split=0.3,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8adb5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 968us/step - loss: 0.3579 - accuracy: 0.9304\n"
     ]
    }
   ],
   "source": [
    "#accuracy of model\n",
    "scores=model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d9736fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.04%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71714186",
   "metadata": {},
   "source": [
    "**iteration-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f415aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 7ms/step - loss: 2.1378 - accuracy: 0.7562 - val_loss: 1.2382 - val_accuracy: 0.6731\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4341 - accuracy: 0.7562 - val_loss: 1.1088 - val_accuracy: 0.6731\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.3338 - accuracy: 0.7562 - val_loss: 1.1000 - val_accuracy: 0.6731\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2716 - accuracy: 0.7562 - val_loss: 1.0244 - val_accuracy: 0.6731\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8353 - accuracy: 0.7562 - val_loss: 0.7529 - val_accuracy: 0.6731\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.7562 - val_loss: 0.6737 - val_accuracy: 0.6731\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6150 - accuracy: 0.7562 - val_loss: 0.6543 - val_accuracy: 0.6731\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5958 - accuracy: 0.7562 - val_loss: 0.6525 - val_accuracy: 0.6731\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.7562 - val_loss: 0.6516 - val_accuracy: 0.6731\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5930 - accuracy: 0.7562 - val_loss: 0.6509 - val_accuracy: 0.6731\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7562 - val_loss: 0.6499 - val_accuracy: 0.6731\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7562 - val_loss: 0.6488 - val_accuracy: 0.6731\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5895 - accuracy: 0.7562 - val_loss: 0.6481 - val_accuracy: 0.6731\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.7562 - val_loss: 0.6473 - val_accuracy: 0.6731\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7562 - val_loss: 0.6471 - val_accuracy: 0.6731\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5863 - accuracy: 0.7562 - val_loss: 0.6466 - val_accuracy: 0.6731\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7562 - val_loss: 0.6465 - val_accuracy: 0.6731\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7562 - val_loss: 0.6462 - val_accuracy: 0.6731\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7562 - val_loss: 0.6456 - val_accuracy: 0.6731\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7562 - val_loss: 0.6454 - val_accuracy: 0.6731\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7562 - val_loss: 0.6450 - val_accuracy: 0.6731\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7562 - val_loss: 0.6448 - val_accuracy: 0.6731\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7562 - val_loss: 0.6443 - val_accuracy: 0.6731\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.7562 - val_loss: 0.6437 - val_accuracy: 0.6731\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7562 - val_loss: 0.6435 - val_accuracy: 0.6731\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7562 - val_loss: 0.6428 - val_accuracy: 0.6731\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7562 - val_loss: 0.6427 - val_accuracy: 0.6731\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.5727 - accuracy: 0.7562 - val_loss: 0.6414 - val_accuracy: 0.6731\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5715 - accuracy: 0.7562 - val_loss: 0.6406 - val_accuracy: 0.6731\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7562 - val_loss: 0.6405 - val_accuracy: 0.6731\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7562 - val_loss: 0.6395 - val_accuracy: 0.6731\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7562 - val_loss: 0.6393 - val_accuracy: 0.6731\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7562 - val_loss: 0.6392 - val_accuracy: 0.6731\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7562 - val_loss: 0.6392 - val_accuracy: 0.6731\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5648 - accuracy: 0.7562 - val_loss: 0.6393 - val_accuracy: 0.6731\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7562 - val_loss: 0.6394 - val_accuracy: 0.6731\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7562 - val_loss: 0.6390 - val_accuracy: 0.6731\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7562 - val_loss: 0.6387 - val_accuracy: 0.6731\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5609 - accuracy: 0.7562 - val_loss: 0.6393 - val_accuracy: 0.6731\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5601 - accuracy: 0.7562 - val_loss: 0.6388 - val_accuracy: 0.6731\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.7562 - val_loss: 0.6393 - val_accuracy: 0.6731\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5580 - accuracy: 0.7562 - val_loss: 0.6387 - val_accuracy: 0.6731\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7562 - val_loss: 0.6386 - val_accuracy: 0.6731\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7562 - val_loss: 0.6382 - val_accuracy: 0.6731\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7562 - val_loss: 0.6364 - val_accuracy: 0.6731\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5542 - accuracy: 0.7562 - val_loss: 0.6364 - val_accuracy: 0.6731\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7562 - val_loss: 0.6363 - val_accuracy: 0.6731\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7562 - val_loss: 0.6368 - val_accuracy: 0.6731\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.7562 - val_loss: 0.6354 - val_accuracy: 0.6731\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7562 - val_loss: 0.6350 - val_accuracy: 0.6731\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7562 - val_loss: 0.6349 - val_accuracy: 0.6731\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7562 - val_loss: 0.6357 - val_accuracy: 0.6731\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7562 - val_loss: 0.6356 - val_accuracy: 0.6731\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5469 - accuracy: 0.7562 - val_loss: 0.6357 - val_accuracy: 0.6731\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5460 - accuracy: 0.7562 - val_loss: 0.6354 - val_accuracy: 0.6731\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.7562 - val_loss: 0.6348 - val_accuracy: 0.6731\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7562 - val_loss: 0.6358 - val_accuracy: 0.6731\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7562 - val_loss: 0.6355 - val_accuracy: 0.6731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7562 - val_loss: 0.6352 - val_accuracy: 0.6731\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7562 - val_loss: 0.6354 - val_accuracy: 0.6731\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7562 - val_loss: 0.6329 - val_accuracy: 0.6731\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7562 - val_loss: 0.6330 - val_accuracy: 0.6731\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7562 - val_loss: 0.6329 - val_accuracy: 0.6731\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7562 - val_loss: 0.6316 - val_accuracy: 0.6731\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7562 - val_loss: 0.6314 - val_accuracy: 0.6731\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7562 - val_loss: 0.6318 - val_accuracy: 0.6731\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7562 - val_loss: 0.6319 - val_accuracy: 0.6731\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7562 - val_loss: 0.6323 - val_accuracy: 0.6731\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7562 - val_loss: 0.6324 - val_accuracy: 0.6731\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7562 - val_loss: 0.6329 - val_accuracy: 0.6731\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7562 - val_loss: 0.6308 - val_accuracy: 0.6731\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7562 - val_loss: 0.6304 - val_accuracy: 0.6731\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7562 - val_loss: 0.6311 - val_accuracy: 0.6731\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7562 - val_loss: 0.6314 - val_accuracy: 0.6731\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7562 - val_loss: 0.6310 - val_accuracy: 0.6731\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7562 - val_loss: 0.6315 - val_accuracy: 0.6731\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7562 - val_loss: 0.6284 - val_accuracy: 0.6731\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7562 - val_loss: 0.6299 - val_accuracy: 0.6731\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5238 - accuracy: 0.7562 - val_loss: 0.6308 - val_accuracy: 0.6731\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7562 - val_loss: 0.6320 - val_accuracy: 0.6731\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5225 - accuracy: 0.7562 - val_loss: 0.6322 - val_accuracy: 0.6731\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.7562 - val_loss: 0.6316 - val_accuracy: 0.6731\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.7562 - val_loss: 0.6243 - val_accuracy: 0.6731\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7562 - val_loss: 0.6257 - val_accuracy: 0.6731\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7562 - val_loss: 0.6281 - val_accuracy: 0.6731\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7562 - val_loss: 0.6245 - val_accuracy: 0.6731\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7562 - val_loss: 0.6240 - val_accuracy: 0.6731\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7562 - val_loss: 0.6258 - val_accuracy: 0.6731\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7562 - val_loss: 0.6273 - val_accuracy: 0.6731\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7562 - val_loss: 0.6306 - val_accuracy: 0.6731\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7562 - val_loss: 0.6297 - val_accuracy: 0.6731\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7562 - val_loss: 0.6252 - val_accuracy: 0.6731\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7562 - val_loss: 0.6237 - val_accuracy: 0.6731\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7562 - val_loss: 0.6256 - val_accuracy: 0.6731\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5094 - accuracy: 0.7562 - val_loss: 0.6264 - val_accuracy: 0.6731\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5086 - accuracy: 0.7562 - val_loss: 0.6283 - val_accuracy: 0.6731\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5074 - accuracy: 0.7562 - val_loss: 0.6264 - val_accuracy: 0.6795\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5065 - accuracy: 0.7590 - val_loss: 0.6282 - val_accuracy: 0.6795\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7590 - val_loss: 0.6259 - val_accuracy: 0.6795\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7590 - val_loss: 0.6283 - val_accuracy: 0.6795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19373614d60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Dense(12,input_dim=24,activation='sigmoid'))\n",
    "model1.add(Dense(8,activation='sigmoid'))\n",
    "model1.add(Dense(1,activation='relu'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model1.fit(x, y, validation_split=0.3, epochs=100, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e27bd535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 997us/step - loss: 0.5414 - accuracy: 0.7350\n",
      "accuracy: 73.50%\n"
     ]
    }
   ],
   "source": [
    "#model accuracy\n",
    "scores1=model1.evaluate(x,y)\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[1], scores1[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc3c55",
   "metadata": {},
   "source": [
    "**iteration-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66c03a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.9213 - accuracy: 0.6620 - val_loss: 1.7087 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.7675 - accuracy: 0.7091 - val_loss: 1.6816 - val_accuracy: 0.6859\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1.6336 - accuracy: 0.7341 - val_loss: 1.5826 - val_accuracy: 0.6859\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1.5407 - accuracy: 0.7396 - val_loss: 1.4082 - val_accuracy: 0.6987\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.4676 - accuracy: 0.7452 - val_loss: 1.3041 - val_accuracy: 0.7051\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1.3269 - accuracy: 0.7341 - val_loss: 1.3018 - val_accuracy: 0.7051\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2854 - accuracy: 0.7424 - val_loss: 1.3002 - val_accuracy: 0.7115\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2725 - accuracy: 0.7452 - val_loss: 1.2997 - val_accuracy: 0.7115\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.2629 - accuracy: 0.7507 - val_loss: 1.3032 - val_accuracy: 0.7051\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.2558 - accuracy: 0.7535 - val_loss: 1.3056 - val_accuracy: 0.6987\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1.2239 - accuracy: 0.7479 - val_loss: 1.2279 - val_accuracy: 0.7051\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1754 - accuracy: 0.7424 - val_loss: 1.2297 - val_accuracy: 0.7115\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1714 - accuracy: 0.7479 - val_loss: 1.2323 - val_accuracy: 0.7051\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1341 - accuracy: 0.7535 - val_loss: 1.2430 - val_accuracy: 0.6987\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1.0918 - accuracy: 0.7590 - val_loss: 1.3158 - val_accuracy: 0.6859\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0831 - accuracy: 0.7618 - val_loss: 1.3288 - val_accuracy: 0.6923\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.0789 - accuracy: 0.7618 - val_loss: 1.3155 - val_accuracy: 0.6987\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1.0754 - accuracy: 0.7618 - val_loss: 1.3122 - val_accuracy: 0.7051\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1.0711 - accuracy: 0.7618 - val_loss: 1.3114 - val_accuracy: 0.7051\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0383 - accuracy: 0.7618 - val_loss: 1.1710 - val_accuracy: 0.7051\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9597 - accuracy: 0.7645 - val_loss: 1.0636 - val_accuracy: 0.6987\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9504 - accuracy: 0.7645 - val_loss: 1.0610 - val_accuracy: 0.7051\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.9465 - accuracy: 0.7701 - val_loss: 1.0657 - val_accuracy: 0.7051\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9427 - accuracy: 0.7673 - val_loss: 1.0776 - val_accuracy: 0.6987\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.9389 - accuracy: 0.7673 - val_loss: 1.0886 - val_accuracy: 0.6987\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9359 - accuracy: 0.7673 - val_loss: 1.2195 - val_accuracy: 0.6987\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.9316 - accuracy: 0.7729 - val_loss: 1.2228 - val_accuracy: 0.6987\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9288 - accuracy: 0.7729 - val_loss: 1.2263 - val_accuracy: 0.6987\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9255 - accuracy: 0.7729 - val_loss: 1.2405 - val_accuracy: 0.6987\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.9220 - accuracy: 0.7729 - val_loss: 1.2962 - val_accuracy: 0.6987\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9194 - accuracy: 0.7729 - val_loss: 1.2947 - val_accuracy: 0.7051\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9166 - accuracy: 0.7756 - val_loss: 1.2976 - val_accuracy: 0.6987\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9137 - accuracy: 0.7756 - val_loss: 1.2918 - val_accuracy: 0.7051\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.7784 - val_loss: 1.2913 - val_accuracy: 0.7051\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8754 - accuracy: 0.7784 - val_loss: 1.3647 - val_accuracy: 0.7115\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8667 - accuracy: 0.7839 - val_loss: 1.2826 - val_accuracy: 0.7115\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8635 - accuracy: 0.7812 - val_loss: 1.2807 - val_accuracy: 0.7115\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8599 - accuracy: 0.7839 - val_loss: 1.2722 - val_accuracy: 0.7115\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8571 - accuracy: 0.7839 - val_loss: 1.2695 - val_accuracy: 0.7179\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8521 - accuracy: 0.7922 - val_loss: 1.1929 - val_accuracy: 0.7179\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8499 - accuracy: 0.7867 - val_loss: 1.1993 - val_accuracy: 0.7179\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8472 - accuracy: 0.7839 - val_loss: 1.1956 - val_accuracy: 0.7179\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8435 - accuracy: 0.7922 - val_loss: 1.1916 - val_accuracy: 0.7244\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8410 - accuracy: 0.7922 - val_loss: 1.1910 - val_accuracy: 0.7244\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.8377 - accuracy: 0.7895 - val_loss: 1.1947 - val_accuracy: 0.7244\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8355 - accuracy: 0.7895 - val_loss: 1.1886 - val_accuracy: 0.7244\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8328 - accuracy: 0.7895 - val_loss: 1.2542 - val_accuracy: 0.7244\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8025 - accuracy: 0.7950 - val_loss: 1.0785 - val_accuracy: 0.7308\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.7949 - accuracy: 0.8061 - val_loss: 1.0855 - val_accuracy: 0.7308\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7899 - accuracy: 0.8089 - val_loss: 1.1582 - val_accuracy: 0.7308\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.7853 - accuracy: 0.8061 - val_loss: 1.1618 - val_accuracy: 0.7244\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7821 - accuracy: 0.8089 - val_loss: 1.1679 - val_accuracy: 0.7244\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7796 - accuracy: 0.8089 - val_loss: 1.2396 - val_accuracy: 0.7244\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7770 - accuracy: 0.8033 - val_loss: 1.2378 - val_accuracy: 0.7244\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7743 - accuracy: 0.8172 - val_loss: 1.1555 - val_accuracy: 0.7244\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7746 - accuracy: 0.8061 - val_loss: 1.1603 - val_accuracy: 0.7244\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7713 - accuracy: 0.8116 - val_loss: 1.1621 - val_accuracy: 0.7244\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7685 - accuracy: 0.8116 - val_loss: 1.1612 - val_accuracy: 0.7308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7665 - accuracy: 0.8144 - val_loss: 1.2302 - val_accuracy: 0.7308\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7642 - accuracy: 0.8033 - val_loss: 1.2295 - val_accuracy: 0.7372\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7621 - accuracy: 0.8089 - val_loss: 1.2272 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7598 - accuracy: 0.8116 - val_loss: 1.2241 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7568 - accuracy: 0.8144 - val_loss: 1.2217 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7575 - accuracy: 0.8172 - val_loss: 1.2161 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7544 - accuracy: 0.8172 - val_loss: 1.2210 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7535 - accuracy: 0.8227 - val_loss: 1.2154 - val_accuracy: 0.7436\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7510 - accuracy: 0.8116 - val_loss: 1.2239 - val_accuracy: 0.7628\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7472 - accuracy: 0.8199 - val_loss: 1.2216 - val_accuracy: 0.7756\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7457 - accuracy: 0.8172 - val_loss: 1.2174 - val_accuracy: 0.7372\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7429 - accuracy: 0.8172 - val_loss: 1.2263 - val_accuracy: 0.7628\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7406 - accuracy: 0.8144 - val_loss: 1.2322 - val_accuracy: 0.7564\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.8199 - val_loss: 1.2255 - val_accuracy: 0.7308\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.8199 - val_loss: 1.2861 - val_accuracy: 0.7372\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7338 - accuracy: 0.8199 - val_loss: 1.2883 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.8199 - val_loss: 1.2867 - val_accuracy: 0.7564\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7294 - accuracy: 0.8227 - val_loss: 1.2843 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.8283 - val_loss: 1.2098 - val_accuracy: 0.7308\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7295 - accuracy: 0.8338 - val_loss: 1.2692 - val_accuracy: 0.7244\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.8338 - val_loss: 1.2650 - val_accuracy: 0.7372\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7226 - accuracy: 0.8283 - val_loss: 1.2654 - val_accuracy: 0.7372\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7193 - accuracy: 0.8227 - val_loss: 1.2675 - val_accuracy: 0.7436\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.8255 - val_loss: 1.2673 - val_accuracy: 0.7372\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7133 - accuracy: 0.8283 - val_loss: 1.2642 - val_accuracy: 0.7372\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7099 - accuracy: 0.8255 - val_loss: 1.2616 - val_accuracy: 0.7436\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.8310 - val_loss: 1.2606 - val_accuracy: 0.7436\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7049 - accuracy: 0.8283 - val_loss: 1.2609 - val_accuracy: 0.7436\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7054 - accuracy: 0.8283 - val_loss: 1.2582 - val_accuracy: 0.7436\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7012 - accuracy: 0.8338 - val_loss: 1.2620 - val_accuracy: 0.7436\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.8366 - val_loss: 1.2610 - val_accuracy: 0.7564\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.8338 - val_loss: 1.1933 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.8560 - val_loss: 1.1947 - val_accuracy: 0.7564\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5883 - accuracy: 0.8476 - val_loss: 1.1870 - val_accuracy: 0.7628\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.8504 - val_loss: 1.1797 - val_accuracy: 0.7564\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5743 - accuracy: 0.8504 - val_loss: 1.1783 - val_accuracy: 0.7628\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5809 - accuracy: 0.8560 - val_loss: 1.1864 - val_accuracy: 0.7564\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.8476 - val_loss: 1.1774 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.8449 - val_loss: 1.1778 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.8476 - val_loss: 1.2790 - val_accuracy: 0.7628\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5171 - accuracy: 0.8449 - val_loss: 1.3083 - val_accuracy: 0.7564\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.8476 - val_loss: 1.3698 - val_accuracy: 0.7628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1937ba65fa0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(12,input_dim=24,activation='relu'))\n",
    "model2.add(Dense(8,activation='relu'))\n",
    "model2.add(Dense(1,activation='relu'))\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model2.fit(x,y,epochs=100, validation_split=0.3,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ab2a0aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.7690 - accuracy: 0.8240\n",
      "accuracy: 82.40%\n"
     ]
    }
   ],
   "source": [
    "#model accuracy\n",
    "scores2=model2.evaluate(x,y)\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ef579",
   "metadata": {},
   "source": [
    "**iteration-4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02b49fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 2.0304 - accuracy: 0.7368 - val_loss: 2.8527 - val_accuracy: 0.6538\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.8857 - accuracy: 0.7368 - val_loss: 2.9717 - val_accuracy: 0.6474\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.7988 - accuracy: 0.7507 - val_loss: 2.8816 - val_accuracy: 0.6474\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.3882 - accuracy: 0.7535 - val_loss: 2.6670 - val_accuracy: 0.6410\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.3002 - accuracy: 0.7590 - val_loss: 2.6566 - val_accuracy: 0.6410\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2529 - accuracy: 0.7618 - val_loss: 2.6519 - val_accuracy: 0.6474\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2407 - accuracy: 0.7673 - val_loss: 2.6506 - val_accuracy: 0.6538\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.2325 - accuracy: 0.7701 - val_loss: 2.6550 - val_accuracy: 0.6474\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.2256 - accuracy: 0.7812 - val_loss: 2.5810 - val_accuracy: 0.6538\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.2192 - accuracy: 0.7895 - val_loss: 2.5828 - val_accuracy: 0.6538\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.2134 - accuracy: 0.7895 - val_loss: 2.5790 - val_accuracy: 0.6474\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2090 - accuracy: 0.7867 - val_loss: 2.5725 - val_accuracy: 0.6538\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.2040 - accuracy: 0.7867 - val_loss: 2.5759 - val_accuracy: 0.6538\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2003 - accuracy: 0.7867 - val_loss: 2.6478 - val_accuracy: 0.6538\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1962 - accuracy: 0.7895 - val_loss: 2.6452 - val_accuracy: 0.6538\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1940 - accuracy: 0.7895 - val_loss: 2.6406 - val_accuracy: 0.6538\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.1537 - accuracy: 0.7950 - val_loss: 2.5576 - val_accuracy: 0.6538\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.1406 - accuracy: 0.7978 - val_loss: 2.5648 - val_accuracy: 0.6538\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.1385 - accuracy: 0.8033 - val_loss: 2.5649 - val_accuracy: 0.6603\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.1351 - accuracy: 0.7978 - val_loss: 2.7282 - val_accuracy: 0.6538\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1320 - accuracy: 0.7978 - val_loss: 2.7920 - val_accuracy: 0.6538\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1291 - accuracy: 0.8006 - val_loss: 2.7916 - val_accuracy: 0.6603\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1253 - accuracy: 0.8006 - val_loss: 2.7917 - val_accuracy: 0.6603\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.1225 - accuracy: 0.8006 - val_loss: 2.8000 - val_accuracy: 0.6667\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1196 - accuracy: 0.8006 - val_loss: 2.7984 - val_accuracy: 0.6667\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.1184 - accuracy: 0.8006 - val_loss: 2.7311 - val_accuracy: 0.6731\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.1153 - accuracy: 0.8006 - val_loss: 2.7876 - val_accuracy: 0.6731\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.1119 - accuracy: 0.8006 - val_loss: 2.7189 - val_accuracy: 0.6731\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1097 - accuracy: 0.8033 - val_loss: 2.7749 - val_accuracy: 0.6731\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1050 - accuracy: 0.8006 - val_loss: 2.7708 - val_accuracy: 0.6731\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.1018 - accuracy: 0.8033 - val_loss: 2.7698 - val_accuracy: 0.6731\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1012 - accuracy: 0.8061 - val_loss: 2.7657 - val_accuracy: 0.6731\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0982 - accuracy: 0.8089 - val_loss: 2.7610 - val_accuracy: 0.6731\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0956 - accuracy: 0.8061 - val_loss: 2.7602 - val_accuracy: 0.6731\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0922 - accuracy: 0.8089 - val_loss: 2.7599 - val_accuracy: 0.6731\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0897 - accuracy: 0.8061 - val_loss: 2.7560 - val_accuracy: 0.6859\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0883 - accuracy: 0.8061 - val_loss: 2.7548 - val_accuracy: 0.6859\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0576 - accuracy: 0.8144 - val_loss: 2.4839 - val_accuracy: 0.6987\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0436 - accuracy: 0.8172 - val_loss: 2.4850 - val_accuracy: 0.6987\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0397 - accuracy: 0.8172 - val_loss: 2.4904 - val_accuracy: 0.6987\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0364 - accuracy: 0.8144 - val_loss: 2.5652 - val_accuracy: 0.6987\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0359 - accuracy: 0.8116 - val_loss: 2.5659 - val_accuracy: 0.6987\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0327 - accuracy: 0.8116 - val_loss: 2.5674 - val_accuracy: 0.6987\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0293 - accuracy: 0.8089 - val_loss: 2.5656 - val_accuracy: 0.6987\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0268 - accuracy: 0.8116 - val_loss: 2.5698 - val_accuracy: 0.6987\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0227 - accuracy: 0.8199 - val_loss: 2.5758 - val_accuracy: 0.7051\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0191 - accuracy: 0.8172 - val_loss: 2.6457 - val_accuracy: 0.6987\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 1.0167 - accuracy: 0.8255 - val_loss: 2.6476 - val_accuracy: 0.7051\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0139 - accuracy: 0.8227 - val_loss: 2.6432 - val_accuracy: 0.7051\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.0116 - accuracy: 0.8255 - val_loss: 2.6416 - val_accuracy: 0.7051\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.0091 - accuracy: 0.8227 - val_loss: 2.6411 - val_accuracy: 0.7051\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 1.0064 - accuracy: 0.8255 - val_loss: 2.6420 - val_accuracy: 0.7051\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 1.0019 - accuracy: 0.8255 - val_loss: 2.6425 - val_accuracy: 0.6987\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.9986 - accuracy: 0.8283 - val_loss: 2.7151 - val_accuracy: 0.6987\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.9939 - accuracy: 0.8283 - val_loss: 2.7123 - val_accuracy: 0.6987\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9917 - accuracy: 0.8310 - val_loss: 2.7137 - val_accuracy: 0.6987\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9879 - accuracy: 0.8310 - val_loss: 2.6441 - val_accuracy: 0.6859\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9861 - accuracy: 0.8366 - val_loss: 2.7113 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9826 - accuracy: 0.8449 - val_loss: 2.6376 - val_accuracy: 0.7051\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.9807 - accuracy: 0.8476 - val_loss: 2.7097 - val_accuracy: 0.6987\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9754 - accuracy: 0.8476 - val_loss: 2.7089 - val_accuracy: 0.6987\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9739 - accuracy: 0.8476 - val_loss: 2.7065 - val_accuracy: 0.7051\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9725 - accuracy: 0.8476 - val_loss: 2.7065 - val_accuracy: 0.7051\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9667 - accuracy: 0.8476 - val_loss: 2.6459 - val_accuracy: 0.7051\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9706 - accuracy: 0.8587 - val_loss: 2.6275 - val_accuracy: 0.7051\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9634 - accuracy: 0.8560 - val_loss: 2.6262 - val_accuracy: 0.7051\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9595 - accuracy: 0.8532 - val_loss: 2.6327 - val_accuracy: 0.7115\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.9578 - accuracy: 0.8587 - val_loss: 2.6272 - val_accuracy: 0.7115\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.9566 - accuracy: 0.8532 - val_loss: 2.6283 - val_accuracy: 0.7051\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9531 - accuracy: 0.8560 - val_loss: 2.6284 - val_accuracy: 0.7179\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9503 - accuracy: 0.8532 - val_loss: 2.6175 - val_accuracy: 0.7179\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9483 - accuracy: 0.8560 - val_loss: 2.6196 - val_accuracy: 0.7115\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.9493 - accuracy: 0.8504 - val_loss: 2.6161 - val_accuracy: 0.6987\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.9622 - accuracy: 0.8504 - val_loss: 2.3832 - val_accuracy: 0.7051\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 1.0158 - accuracy: 0.8504 - val_loss: 2.4223 - val_accuracy: 0.7500\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9744 - accuracy: 0.8532 - val_loss: 2.4099 - val_accuracy: 0.7115\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9716 - accuracy: 0.8338 - val_loss: 2.4838 - val_accuracy: 0.7179\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9612 - accuracy: 0.8421 - val_loss: 2.4588 - val_accuracy: 0.7308\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.9532 - accuracy: 0.8615 - val_loss: 2.4611 - val_accuracy: 0.7436\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.9496 - accuracy: 0.8698 - val_loss: 2.4512 - val_accuracy: 0.7436\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.9474 - accuracy: 0.8670 - val_loss: 2.4530 - val_accuracy: 0.7436\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9436 - accuracy: 0.8698 - val_loss: 2.5265 - val_accuracy: 0.7372\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9411 - accuracy: 0.8698 - val_loss: 2.5256 - val_accuracy: 0.7308\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.9394 - accuracy: 0.8643 - val_loss: 2.5226 - val_accuracy: 0.7308\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.9374 - accuracy: 0.8698 - val_loss: 2.5207 - val_accuracy: 0.7372\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9359 - accuracy: 0.8726 - val_loss: 2.5238 - val_accuracy: 0.7372\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9344 - accuracy: 0.8698 - val_loss: 2.4365 - val_accuracy: 0.7372\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9334 - accuracy: 0.8670 - val_loss: 2.4424 - val_accuracy: 0.7372\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9321 - accuracy: 0.8698 - val_loss: 2.5221 - val_accuracy: 0.7372\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.9297 - accuracy: 0.8698 - val_loss: 2.5183 - val_accuracy: 0.7372\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9265 - accuracy: 0.8753 - val_loss: 2.5128 - val_accuracy: 0.7308\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9279 - accuracy: 0.8726 - val_loss: 2.5146 - val_accuracy: 0.7436\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9238 - accuracy: 0.8726 - val_loss: 2.5180 - val_accuracy: 0.7372\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9248 - accuracy: 0.8698 - val_loss: 2.5313 - val_accuracy: 0.7500\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.9213 - accuracy: 0.8698 - val_loss: 2.5193 - val_accuracy: 0.7308\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9176 - accuracy: 0.8726 - val_loss: 2.5968 - val_accuracy: 0.7244\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.9127 - accuracy: 0.8781 - val_loss: 2.5267 - val_accuracy: 0.7179\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9147 - accuracy: 0.8698 - val_loss: 2.5361 - val_accuracy: 0.7308\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9087 - accuracy: 0.8781 - val_loss: 2.5135 - val_accuracy: 0.7244\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.9034 - accuracy: 0.8837 - val_loss: 2.5072 - val_accuracy: 0.7244\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.9040 - accuracy: 0.8837 - val_loss: 2.5024 - val_accuracy: 0.7244\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9009 - accuracy: 0.8920 - val_loss: 2.4981 - val_accuracy: 0.7244\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.8974 - accuracy: 0.8892 - val_loss: 2.4990 - val_accuracy: 0.7244\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.8964 - accuracy: 0.8920 - val_loss: 2.5071 - val_accuracy: 0.7244\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.8927 - accuracy: 0.8920 - val_loss: 2.5015 - val_accuracy: 0.7308\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.8898 - accuracy: 0.8947 - val_loss: 2.6526 - val_accuracy: 0.7372\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8884 - accuracy: 0.8920 - val_loss: 2.5772 - val_accuracy: 0.7308\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8864 - accuracy: 0.8920 - val_loss: 2.5807 - val_accuracy: 0.7372\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8859 - accuracy: 0.8920 - val_loss: 2.5772 - val_accuracy: 0.7372\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8864 - accuracy: 0.8947 - val_loss: 2.6437 - val_accuracy: 0.7372\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8815 - accuracy: 0.8947 - val_loss: 2.6496 - val_accuracy: 0.7372\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8805 - accuracy: 0.8920 - val_loss: 2.6448 - val_accuracy: 0.7372\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8907 - accuracy: 0.8864 - val_loss: 2.5924 - val_accuracy: 0.7372\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8811 - accuracy: 0.8947 - val_loss: 2.6374 - val_accuracy: 0.7436\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8773 - accuracy: 0.8864 - val_loss: 2.5684 - val_accuracy: 0.7436\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8611 - accuracy: 0.8975 - val_loss: 2.1690 - val_accuracy: 0.7308\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.8933 - accuracy: 0.8753 - val_loss: 2.2205 - val_accuracy: 0.7885\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8200 - accuracy: 0.8864 - val_loss: 2.2630 - val_accuracy: 0.7821\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.9495 - accuracy: 0.8670 - val_loss: 2.1818 - val_accuracy: 0.7628\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.8350 - accuracy: 0.8726 - val_loss: 2.3613 - val_accuracy: 0.7692\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.8176 - accuracy: 0.8837 - val_loss: 2.2768 - val_accuracy: 0.7692\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.8113 - accuracy: 0.8920 - val_loss: 2.2703 - val_accuracy: 0.7692\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.8067 - accuracy: 0.8920 - val_loss: 2.3520 - val_accuracy: 0.7564\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.8027 - accuracy: 0.9086 - val_loss: 2.2726 - val_accuracy: 0.7628\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.7984 - accuracy: 0.9058 - val_loss: 2.2791 - val_accuracy: 0.7756\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.9003 - val_loss: 2.2828 - val_accuracy: 0.7692\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7954 - accuracy: 0.9030 - val_loss: 2.2846 - val_accuracy: 0.7692\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.7916 - accuracy: 0.9030 - val_loss: 2.2838 - val_accuracy: 0.7692\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.7897 - accuracy: 0.9058 - val_loss: 2.3536 - val_accuracy: 0.7692\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.7880 - accuracy: 0.9030 - val_loss: 2.2986 - val_accuracy: 0.7692\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.7853 - accuracy: 0.9030 - val_loss: 2.4367 - val_accuracy: 0.7628\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.7829 - accuracy: 0.9030 - val_loss: 2.4357 - val_accuracy: 0.7692\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.7823 - accuracy: 0.9030 - val_loss: 2.4343 - val_accuracy: 0.7564\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.7816 - accuracy: 0.9030 - val_loss: 2.4339 - val_accuracy: 0.7692\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.7809 - accuracy: 0.9003 - val_loss: 2.4339 - val_accuracy: 0.7628\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.7776 - accuracy: 0.9030 - val_loss: 2.4331 - val_accuracy: 0.7564\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.7766 - accuracy: 0.9030 - val_loss: 2.4311 - val_accuracy: 0.7821\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.7750 - accuracy: 0.9058 - val_loss: 2.4311 - val_accuracy: 0.7821\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.7743 - accuracy: 0.9030 - val_loss: 2.4308 - val_accuracy: 0.7821\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.7724 - accuracy: 0.9086 - val_loss: 2.4361 - val_accuracy: 0.7756\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.7730 - accuracy: 0.9058 - val_loss: 2.4276 - val_accuracy: 0.7821\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.7719 - accuracy: 0.9058 - val_loss: 2.3558 - val_accuracy: 0.7756\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.7710 - accuracy: 0.9058 - val_loss: 2.3493 - val_accuracy: 0.7756\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.7710 - accuracy: 0.9058 - val_loss: 2.3461 - val_accuracy: 0.7756\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.9114 - val_loss: 2.1237 - val_accuracy: 0.7628\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.9197 - val_loss: 2.0519 - val_accuracy: 0.7756\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5737 - accuracy: 0.9141 - val_loss: 2.0489 - val_accuracy: 0.7821\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.9197 - val_loss: 2.0507 - val_accuracy: 0.7885\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.5679 - accuracy: 0.9197 - val_loss: 2.0467 - val_accuracy: 0.7756\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.5669 - accuracy: 0.9169 - val_loss: 2.0503 - val_accuracy: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1937cb5b1c0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Dense(12,input_dim=24,activation='relu'))\n",
    "model3.add(Dense(8,activation='relu'))\n",
    "model3.add(Dense(1,activation='relu'))\n",
    "model3.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model3.fit(x,y,epochs=150, validation_split=0.3,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8a4fa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0112 - accuracy: 0.8801\n",
      "accuracy: 88.01%\n"
     ]
    }
   ],
   "source": [
    "scores3 = model3.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model3.metrics_names[1], scores3[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hence here we can see that the best of all iteration is first one where accuracy of the system came as 92.65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7a6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698be91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204c7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
